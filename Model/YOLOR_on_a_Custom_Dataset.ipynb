{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icONSOTY9AmP"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzhKhmQQpKKf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bs156q-9Fpe"
      },
      "outputs": [],
      "source": [
        "# clone YOLOR repository\n",
        "!git clone https://github.com/roboflow-ai/yolor\n",
        "%cd yolor\n",
        "!git reset --hard eb3ef0b7472413d6740f5cde39beb1a2f5b8b5d1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy4tuOqP9efo"
      },
      "outputs": [],
      "source": [
        "# Install necessary dependencies\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w23WgLFB-TZ-"
      },
      "outputs": [],
      "source": [
        "# Install Mish CUDA\n",
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda\n",
        "!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n",
        "!python setup.py build install\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWJkbCp8Yoj_"
      },
      "outputs": [],
      "source": [
        "# Install PyTorch Wavelets\n",
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "%cd pytorch_wavelets\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYI5O1mW98Ji"
      },
      "source": [
        "# Download Correctly Formatted Custom Dataset \n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n",
        "\n",
        "![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GecVEGw4mMz"
      },
      "outputs": [],
      "source": [
        "#follow the link below to get your download code from from Roboflow\n",
        "!pip install -q roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOqdKhc4-vOK"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolor\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"V3vC6ZBPImhlrMFS6CUd\")\n",
        "project = rf.workspace(\"rdd-blf4r\").project(\"rdd-h9ax0\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eltS69vHDldw",
        "outputId": "c4008d52-b5d5-4291-c5a6-245b5fb26eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "names:\n",
            "- D00\n",
            "- D10\n",
            "- D20\n",
            "- D40\n",
            "- D43\n",
            "- D44\n",
            "- D50\n",
            "nc: 7\n",
            "train: RDD-2/train/images\n",
            "val: RDD-2/valid/images\n"
          ]
        }
      ],
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCs0G_xoD0aq"
      },
      "source": [
        "# Prepare Pre-Trained Weights for YOLOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JepT8h7EA_j"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolor\n",
        "!bash scripts/get_pretrain.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBjYNGD4ER_4"
      },
      "source": [
        "# Write YOLOR Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cy8NlkoKg9lC"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\") as f:\n",
        "    dataMap = yaml.safe_load(f)\n",
        "\n",
        "num_classes = len(dataMap['names'])\n",
        "num_filters = (num_classes + 5) * 3\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2XOWgwAg5kV"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolor/cfg/yolor_p6.cfg\n",
        "\n",
        "[net]\n",
        "batch=64\n",
        "subdivisions=8\n",
        "width=1280\n",
        "height=1280\n",
        "channels=3\n",
        "momentum=0.949\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = 500500\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "mosaic=1\n",
        "\n",
        "\n",
        "# ============ Backbone ============ #\n",
        "\n",
        "# Stem \n",
        "\n",
        "# P1\n",
        "\n",
        "# Downsample\n",
        "\n",
        "# 0\n",
        "[reorg]\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P2\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=64\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 16 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P3\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=128\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 43 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P4\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=192\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 70 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P5\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=256\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 85 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P6\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=320\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 100 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Backbone ============ #\n",
        "\n",
        "# ============ Neck ============ #\n",
        "\n",
        "# CSPSPP\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "### SPP ###\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=5\n",
        "\n",
        "[route]\n",
        "layers=-2\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=9\n",
        "\n",
        "[route]\n",
        "layers=-4\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=13\n",
        "\n",
        "[route]\n",
        "layers=-1,-3,-5,-6\n",
        "### End SPP ###\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -13\n",
        "\n",
        "# 115 (previous+6+5+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# End of CSPSPP\n",
        "\n",
        "\n",
        "# FPN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 85\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 131 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 70\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 147 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 43\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 163 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 147\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 176 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 131\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 189 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-6\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 115\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 202 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Neck ============ #\n",
        "\n",
        "# 203\n",
        "[implicit_add]\n",
        "filters=256\n",
        "\n",
        "# 204\n",
        "[implicit_add]\n",
        "filters=384\n",
        "\n",
        "# 205\n",
        "[implicit_add]\n",
        "filters=512\n",
        "\n",
        "# 206\n",
        "[implicit_add]\n",
        "filters=640\n",
        "\n",
        "# 207\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 208\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 209\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 210\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# ============ Head ============ #\n",
        "\n",
        "# YOLO-3\n",
        "\n",
        "[route]\n",
        "layers = 163\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=203\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=207\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-4\n",
        "\n",
        "[route]\n",
        "layers = 176\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=384\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=204\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=208\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-5\n",
        "\n",
        "[route]\n",
        "layers = 189\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=205\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=209\n",
        "\n",
        "[yolo]\n",
        "mask = 6,7,8\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-6\n",
        "\n",
        "[route]\n",
        "layers = 202\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=640\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=206\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=210\n",
        "\n",
        "[yolo]\n",
        "mask = 9,10,11\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "# ============ End of Head ============ #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLldIGy2ERgB"
      },
      "outputs": [],
      "source": [
        "%cat /content/yolor/cfg/yolor_p6.cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6t4nA4wWr8v"
      },
      "source": [
        "# Train Custom YOLOR Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: We can specify the pretrained weights we downloaded up above with the shell script)\n",
        "- **name:** result names\n",
        "-**hyp:** Define the hyperparamters for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w0P5Pw-pd9a"
      },
      "outputs": [],
      "source": [
        "%cp /content/drive/MyDrive/yolor_p6.pt /content -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7PKH6ufhkwu"
      },
      "outputs": [],
      "source": [
        "%cp /content/drive/MyDrive/runs /content/yolor -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OqG-CDJZEiw2"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolor\n",
        "!python train.py --batch-size 8 --img 416 416 --data {dataset.location}/data.yaml --cfg cfg/yolor_p6.cfg --weights '/content/yolor_p6.pt' --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 100 --resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV-YoyJpYfeN"
      },
      "outputs": [],
      "source": [
        "%cp /content/yolor/runs /content/drive/MyDrive -r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAbe94smXcg0"
      },
      "source": [
        "# Evaluate Custom YOLOR Detector Performance\n",
        "\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolor_p6`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Kha-ehkX1qP"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGnkowATX4ZS"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/results.png', width=1000)  # view results.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyp7zrtBX6wc"
      },
      "outputs": [],
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDDz3cWgq4gQ"
      },
      "outputs": [],
      "source": [
        "print(\"AUGMENTED DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqYf31oCYYRn"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwuHFc3nYf7J"
      },
      "outputs": [],
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liYDNniHYiKq"
      },
      "outputs": [],
      "source": [
        "%ls runs/train/yolor_p6/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLG0HPpbtpK0"
      },
      "outputs": [],
      "source": [
        "# Create names file for model\n",
        "import yaml\n",
        "import ast\n",
        "with open(\"../data.yaml\", 'r') as stream:\n",
        "    names = str(yaml.safe_load(stream)['names'])\n",
        "\n",
        "namesFile = open(\"../data.names\", \"w+\")\n",
        "names = ast.literal_eval(names)\n",
        "for name in names:\n",
        "  namesFile.write(name +'\\n')\n",
        "namesFile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfObNHTCYqih"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights \"runs/train/yolor_p6/weights/best_overall.pt\" --conf 0.5 --source ../test/images --names ../data.names --cfg cfg/yolor_p6.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBeuZJA4s2Zh"
      },
      "outputs": [],
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolor/inference/output/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUnMCThYM3W"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP8-UrwiYP8j"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ-zspK3YQlr"
      },
      "outputs": [],
      "source": [
        "%cp /content/yolor/runs/train/yolor_p6/weights/best.pt /content/gdrive/My\\ Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQrUGu9nYI-T"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "Hope you enjoyed this!\n",
        "\n",
        "--Team [Roboflow](https://roboflow.ai)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Bản_sao_của_Training_YOLOR_on_a_Custom_Dataset_(1) (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
