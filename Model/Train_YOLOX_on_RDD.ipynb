{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xru6s6p6A18s"
      },
      "source": [
        "# How to Train YOLOX on Custom Objects\n",
        "\n",
        "This tutorial is based on the [YOLOX repository](https://github.com/Megvii-BaseDetection/YOLOX) by [the Megvii Team](https://github.com/Megvii-BaseDetection). This notebook shows training on **your own custom objects**. Many thanks to the Megvii Team for putting this repository together - we hope that in combination with clean data management tools at Roboflow, this technologoy will become easily accessible to any developer wishing to use computer vision in their projects.\n",
        "\n",
        "### Accompanying Blog Post\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [How to Train YOLOX](blog.roboflow.com/how-to-train-yolox-on-a-custom-dataset/), concurrently.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "In this tutorial, we will walk through the steps required to train YOLOR on your custom objects. We use a [public blood cell detection dataset](https://public.roboflow.ai/object-detection/bccd), which is open source and free to use. You can also use this notebook on your own data. We will use Roboflow to preprocess our images.\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOX dependencies\n",
        "* Download and Prepare custom YOLOX object detection data\n",
        "* Download Pre-Trained Weights for YOLOX\n",
        "* Run YOLOX training\n",
        "* Evaluate YOLOX performance\n",
        "* Run YOLOX inference on test images\n",
        "* Export saved YOLOX weights for future inference\n",
        "\n",
        "### **About**\n",
        "\n",
        "[Roboflow](https://roboflow.com) enables teams to deploy custom computer vision models quickly and accurately. Convert data from to annotation format, assess dataset health, preprocess, augment, and more. It's free for your first 1000 source images.\n",
        "\n",
        "**Looking for a vision model available via API without hassle? Try Roboflow Train.**\n",
        "\n",
        "![Roboflow Wordmark](https://i.imgur.com/dcLNMhV.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfVlxlYYBR6z"
      },
      "source": [
        "# Install YOLOX Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igwruhYxE_a7",
        "outputId": "36f20519-c69b-4d0c-fbc3-fda049aae669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOX'...\n",
            "remote: Enumerating objects: 795, done.\u001b[K\n",
            "remote: Total 795 (delta 0), reused 0 (delta 0), pack-reused 795\u001b[K\n",
            "Receiving objects: 100% (795/795), 5.77 MiB | 22.65 MiB/s, done.\n",
            "Resolving deltas: 100% (424/424), done.\n",
            "/content/YOLOX\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.11.0+cu113)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.1.2.30)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.64.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.12.0+cu113)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/roboflow-ai/YOLOX.git\n",
        "%cd YOLOX\n",
        "!pip3 install -U pip && pip3 install -r requirements.txt\n",
        "!pip3 install -v -e .  \n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "# May need to change in the future if Colab no longer uses CUDA 11.0\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llsu3xhVBZYC"
      },
      "source": [
        "## Install Nvidia Apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksHd57LFFMzK"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-EidleBfeB"
      },
      "source": [
        "## Install PyCocoTools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwuWoBOxFV6v"
      },
      "outputs": [],
      "source": [
        "!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdiT0rJBmRA"
      },
      "source": [
        "# Download your Data\n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**Pascal VOC**\" export format.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJkU0eH-VgCn"
      },
      "outputs": [],
      "source": [
        "#to get your roboflow code below please follow the link output by this cell\n",
        "!pip -q install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"voc\", notebook=\"yolox\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp1L8zdwGo_j"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"V3vC6ZBPImhlrMFS6CUd\")\n",
        "project = rf.workspace(\"rdd-blf4r\").project(\"rdd-h9ax0\")\n",
        "dataset = project.version(1).download(\"voc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr4cOxxbVuHB"
      },
      "outputs": [],
      "source": [
        "%cd YOLOX/\n",
        "!ln -s {dataset.location}/train/ ./datasets/VOCdevkit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZSFjXLByrv"
      },
      "source": [
        "## Format Your Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xTRtDWrIw_D"
      },
      "outputs": [],
      "source": [
        "%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2007\"\n",
        "!python3 voc_txt.py \"/content/YOLOX/datasets/VOCdevkit/\"\n",
        "%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2012\"\n",
        "!cp -r \"/content/YOLOX/datasets/VOCdevkit/VOC2007/.\" \"/content/YOLOX/datasets/VOCdevkit/VOC2012\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW8iyuMyB3bc"
      },
      "source": [
        "## Change the Classes\n",
        "Make sure you change the classes based on what your dataset. To ensure that the training process will function as intended, write the classes in lowercase with no whitespace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rohuAE541Nug"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h5PM8Ft1OjG"
      },
      "outputs": [],
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py\n",
        "\n",
        "VOC_CLASSES = (\n",
        "  \"d00\",\n",
        "  \"d10\",\n",
        "  \"d20\",\n",
        "  \"d40\",\n",
        "  \"d43\",\n",
        "  \"d44\",\n",
        "  \"d50\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lu6_LzErQRSU"
      },
      "outputs": [],
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py\n",
        "\n",
        "COCO_CLASSES = (\n",
        "  \"d00\",\n",
        "  \"d10\",\n",
        "  \"d20\",\n",
        "  \"d40\",\n",
        "  \"d43\",\n",
        "  \"d44\",\n",
        "  \"d50\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uAaf5AKSE_E"
      },
      "source": [
        "Set the number of classes you have in your dataset in te `NUM_CLASSES` variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxA0JmWqwU_M"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 7\n",
        "!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiYvw_GGKaro"
      },
      "source": [
        "# Download Pretrained Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsOCh9hRKbIw"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!wget https://github.com/Megvii-BaseDetection/storage/releases/download/0.0.1/yolox_s.pth\n",
        "%cd /content/YOLOX/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TabCpJOCRti"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5h536amH32Z"
      },
      "outputs": [],
      "source": [
        "!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 16 --fp16 -o -c /content/yolox_s.pth "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjsuFDICVov"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE5oWuEOICAF"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/latest_ckpt.pth.tar\"\n",
        "!python3 tools/eval.py -n  yolox-s -c {MODEL_PATH} -b 64 -d 1 --conf 0.001 -f exps/example/yolox_voc/yolox_voc_s.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnFRJEa7CaPe"
      },
      "source": [
        "# Test the Model\n",
        "Make sure you replace the `TEST_IMAGE_PATH` variable with a test image from your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIXoCCwkMjpK"
      },
      "outputs": [],
      "source": [
        "TEST_IMAGE_PATH = \"/content/valid/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg\"\n",
        "!python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py -c {MODEL_PATH} --path {TEST_IMAGE_PATH} --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7nX2nwWCper"
      },
      "source": [
        "# Visualize the Predictions\n",
        "Make sure you replace the `OUTPUT_IMAGE_PATH` with the respective path of the image output. This path can be found somewhere in the `YOLOX_outputs` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3_kOK2cZtJK"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_08_01_19_51_59/BloodImage_00057_jpg.rf.1ee93e9ec4d76cfaddaa7df70456c376.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbMKDkxPWoD"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlZf3KlMPYPS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDrqgjePPaXK"
      },
      "outputs": [],
      "source": [
        "%cp {MODEL_PATH} /content/gdrive/My\\ Drive"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of Train YOLOX on a Custom Dataset - YouTube.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}