{"cells":[{"cell_type":"markdown","metadata":{"id":"icONSOTY9AmP"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --\u003e Change Runtime Type --\u003e Hardware accelerator --\u003e GPU)_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14560,"status":"ok","timestamp":1655877866328,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"gzhKhmQQpKKf","outputId":"daffa044-5ed7-4cd2-f2fb-b4e668a830d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1064,"status":"ok","timestamp":1655877867382,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"6bs156q-9Fpe","outputId":"2a148e61-9ca6-486f-84dc-13f95604c00f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolor'...\n","remote: Enumerating objects: 387, done.\u001b[K\n","remote: Total 387 (delta 0), reused 0 (delta 0), pack-reused 387\u001b[K\n","Receiving objects: 100% (387/387), 2.97 MiB | 14.54 MiB/s, done.\n","Resolving deltas: 100% (173/173), done.\n","/content/yolor\n","HEAD is now at eb3ef0b indentation\n"]}],"source":["# clone YOLOR repository\n","!git clone https://github.com/roboflow-ai/yolor\n","%cd yolor\n","!git reset --hard eb3ef0b7472413d6740f5cde39beb1a2f5b8b5d1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112855,"status":"ok","timestamp":1655877980234,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"fy4tuOqP9efo","outputId":"5fe7a9e4-149e-4798-cba0-3a41e6b79ce5"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████████████████████████| 596 kB 4.9 MB/s \n","\u001b[K     |████████████████████████████████| 776.7 MB 4.3 kB/s \n","\u001b[K     |████████████████████████████████| 12.7 MB 44.9 MB/s \n","\u001b[K     |████████████████████████████████| 1.5 MB 62.8 MB/s \n","\u001b[?25h  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n","fastai 2.6.3 requires torchvision\u003e=0.8.2, but you have torchvision 0.8.1 which is incompatible.\u001b[0m\n"]}],"source":["# Install necessary dependencies\n","!pip install -qr requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61233,"status":"ok","timestamp":1655878041456,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"w23WgLFB-TZ-","outputId":"f66601ac-811f-4603-d6d0-216c617c0e0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'mish-cuda'...\n","remote: Enumerating objects: 195, done.\u001b[K\n","remote: Counting objects: 100% (88/88), done.\u001b[K\n","remote: Compressing objects: 100% (75/75), done.\u001b[K\n","remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\n","Receiving objects: 100% (195/195), 208.77 KiB | 2.78 MiB/s, done.\n","Resolving deltas: 100% (56/56), done.\n","/content/yolor/mish-cuda\n","HEAD is now at 6f38976 Update README.md\n","/usr/lib/python3.7/distutils/extension.py:131: UserWarning: Unknown Extension options: 'headers'\n","  warnings.warn(msg)\n","running build\n","running build_py\n","creating build\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/mish_cuda\n","copying src/mish_cuda/__init__.py -\u003e build/lib.linux-x86_64-3.7/mish_cuda\n","running egg_info\n","creating src/mish_cuda.egg-info\n","writing src/mish_cuda.egg-info/PKG-INFO\n","writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\n","writing requirements to src/mish_cuda.egg-info/requires.txt\n","writing top-level names to src/mish_cuda.egg-info/top_level.txt\n","writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n","/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","  warnings.warn(msg.format('we could not find ninja.'))\n","adding license file 'LICENSE'\n","writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n","running build_ext\n","building 'mish_cuda._C' extension\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/csrc\n","creating build/temp.linux-x86_64-3.7/csrc/cpu\n","creating build/temp.linux-x86_64-3.7/csrc/cuda\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/CPUApplyUtils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[Kcsrc/cpu/mish_cpu.cpp:3\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) \u003e= grain_size)\n"," \n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[Kcsrc/cuda/mish_cuda.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) \u003e= grain_size)\n"," \n","/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++14\n","/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n","\n","/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n","\n","/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n","\n","/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n","\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n","running install\n","running bdist_egg\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/mish_cuda\n","copying build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so -\u003e build/bdist.linux-x86_64/egg/mish_cuda\n","copying build/lib.linux-x86_64-3.7/mish_cuda/__init__.py -\u003e build/bdist.linux-x86_64/egg/mish_cuda\n","byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-37.pyc\n","creating stub loader for mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n","byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/mish_cuda.egg-info/PKG-INFO -\u003e build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/mish_cuda.egg-info/SOURCES.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/mish_cuda.egg-info/dependency_links.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/mish_cuda.egg-info/not-zip-safe -\u003e build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/mish_cuda.egg-info/requires.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO\n","copying src/mish_cuda.egg-info/top_level.txt -\u003e build/bdist.linux-x86_64/egg/EGG-INFO\n","writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n","creating dist\n","creating 'dist/mish_cuda-0.0.3-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n","creating /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n","Extracting mish_cuda-0.0.3-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n","Adding mish-cuda 0.0.3 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n","Processing dependencies for mish-cuda==0.0.3\n","Searching for torch==1.7.0\n","Best match: torch 1.7.0\n","Adding torch 1.7.0 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for numpy==1.21.6\n","Best match: numpy 1.21.6\n","Adding numpy 1.21.6 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.7 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for typing-extensions==4.1.1\n","Best match: typing-extensions 4.1.1\n","Adding typing-extensions 4.1.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for dataclasses==0.6\n","Best match: dataclasses 0.6\n","Adding dataclasses 0.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for future==0.16.0\n","Best match: future 0.16.0\n","Adding future 0.16.0 to easy-install.pth file\n","Installing futurize script to /usr/local/bin\n","Installing pasteurize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Finished processing dependencies for mish-cuda==0.0.3\n","/content/yolor\n"]}],"source":["# Install Mish CUDA\n","!git clone https://github.com/JunnYu/mish-cuda\n","%cd mish-cuda\n","!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n","!python setup.py build install\n","%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6543,"status":"ok","timestamp":1655878047991,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"MWJkbCp8Yoj_","outputId":"c556e7d1-8157-42af-ebcb-edb5d8e4ee6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'pytorch_wavelets'...\n","remote: Enumerating objects: 972, done.\u001b[K\n","remote: Counting objects: 100% (136/136), done.\u001b[K\n","remote: Compressing objects: 100% (91/91), done.\u001b[K\n","remote: Total 972 (delta 75), reused 89 (delta 45), pack-reused 836\u001b[K\n","Receiving objects: 100% (972/972), 6.80 MiB | 25.98 MiB/s, done.\n","Resolving deltas: 100% (659/659), done.\n","/content/yolor/pytorch_wavelets\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/yolor/pytorch_wavelets\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.21.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.7.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch-\u003epytorch-wavelets==1.3.0) (4.1.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch-\u003epytorch-wavelets==1.3.0) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch-\u003epytorch-wavelets==1.3.0) (0.6)\n","Building wheels for collected packages: pytorch-wavelets\n","  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54869 sha256=54a742f5d04c5fce04175c3eb9199860520f2d307a7f3d0a5d660f41def27341\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qpxe0vh7/wheels/68/d6/0a/629cb6c68e1577155ab73a47758996d9ab26f15ba622561e28\n","Successfully built pytorch-wavelets\n","Installing collected packages: pytorch-wavelets\n","Successfully installed pytorch-wavelets-1.3.0\n","/content/yolor\n"]}],"source":["# Install PyTorch Wavelets\n","!git clone https://github.com/fbcotter/pytorch_wavelets\n","%cd pytorch_wavelets\n","!pip install .\n","%cd .."]},{"cell_type":"markdown","metadata":{"id":"TYI5O1mW98Ji"},"source":["# Download Correctly Formatted Custom Dataset \n","\n","We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n","\n","To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/).\n","\n","![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14678,"status":"ok","timestamp":1655878062666,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"8GecVEGw4mMz","outputId":"5f0ef43e-ae7e-4bab-c5e5-94e693ccba3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l\r\u001b[K     |██▎                             | 10 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 145 kB 4.9 MB/s \n","\u001b[K     |████████████████████████████████| 178 kB 45.5 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 52.6 MB/s \n","\u001b[K     |████████████████████████████████| 67 kB 2.1 MB/s \n","\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n","\u001b[K     |████████████████████████████████| 138 kB 75.8 MB/s \n","\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n","\u001b[?25h  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n","fastai 2.6.3 requires torchvision\u003e=0.8.2, but you have torchvision 0.8.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug\u003c0.2.7,\u003e=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5\u0026ref=roboflow-yolor\n"]}],"source":["#follow the link below to get your download code from from Roboflow\n","!pip install -q roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolor\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306859,"status":"ok","timestamp":1655878369520,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"HOqdKhc4-vOK","outputId":"ee119bcc-979e-421a-e9ec-5dc44467b405"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolor\n","loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in RDD-2 to yolov5pytorch: 100% [859191943 / 859191943] bytes\n"]},{"name":"stderr","output_type":"stream","text":["Extracting Dataset Version Zip to RDD-2 in yolov5pytorch:: 100%|██████████| 47318/47318 [00:37\u003c00:00, 1261.86it/s]\n"]}],"source":["%cd /content/yolor\n","#after following the link above, recieve python code with these fields filled in\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"V3vC6ZBPImhlrMFS6CUd\")\n","project = rf.workspace(\"rdd-blf4r\").project(\"rdd-h9ax0\")\n","dataset = project.version(2).download(\"yolov5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1655878369521,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"eltS69vHDldw","outputId":"c4008d52-b5d5-4291-c5a6-245b5fb26eae"},"outputs":[{"name":"stdout","output_type":"stream","text":["names:\n","- D00\n","- D10\n","- D20\n","- D40\n","- D43\n","- D44\n","- D50\n","nc: 7\n","train: RDD-2/train/images\n","val: RDD-2/valid/images\n"]}],"source":["# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","%cat {dataset.location}/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"GCs0G_xoD0aq"},"source":["# Prepare Pre-Trained Weights for YOLOR"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1655878369521,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"8JepT8h7EA_j","outputId":"106ce3fc-e76a-440f-ae8a-d81d3ec051d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolor\n","awk: cannot open ./cookie (No such file or directory)\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2324    0  2324    0     0  20385      0 --:--:-- --:--:-- --:--:-- 20385\n","rm: cannot remove './cookie': No such file or directory\n","awk: cannot open ./cookie (No such file or directory)\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  2324    0  2324    0     0  18156      0 --:--:-- --:--:-- --:--:-- 18156\n","rm: cannot remove './cookie': No such file or directory\n"]}],"source":["%cd /content/yolor\n","!bash scripts/get_pretrain.sh"]},{"cell_type":"markdown","metadata":{"id":"PBjYNGD4ER_4"},"source":["# Write YOLOR Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cy8NlkoKg9lC"},"outputs":[],"source":["import yaml\n","with open(dataset.location + \"/data.yaml\") as f:\n","    dataMap = yaml.safe_load(f)\n","\n","num_classes = len(dataMap['names'])\n","num_filters = (num_classes + 5) * 3\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p2XOWgwAg5kV"},"outputs":[],"source":["%%writetemplate /content/yolor/cfg/yolor_p6.cfg\n","\n","[net]\n","batch=64\n","subdivisions=8\n","width=1280\n","height=1280\n","channels=3\n","momentum=0.949\n","decay=0.0005\n","angle=0\n","saturation = 1.5\n","exposure = 1.5\n","hue=.1\n","\n","learning_rate=0.00261\n","burn_in=1000\n","max_batches = 500500\n","policy=steps\n","steps=400000,450000\n","scales=.1,.1\n","\n","mosaic=1\n","\n","\n","# ============ Backbone ============ #\n","\n","# Stem \n","\n","# P1\n","\n","# Downsample\n","\n","# 0\n","[reorg]\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P2\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=64\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-12\n","\n","# Transition last\n","\n","# 16 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P3\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=128\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-24\n","\n","# Transition last\n","\n","# 43 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P4\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=384\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=192\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-24\n","\n","# Transition last\n","\n","# 70 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=384\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P5\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=512\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=256\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-12\n","\n","# Transition last\n","\n","# 85 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=512\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P6\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=640\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=320\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-12\n","\n","# Transition last\n","\n","# 100 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=640\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# ============ End of Backbone ============ #\n","\n","# ============ Neck ============ #\n","\n","# CSPSPP\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","### SPP ###\n","[maxpool]\n","stride=1\n","size=5\n","\n","[route]\n","layers=-2\n","\n","[maxpool]\n","stride=1\n","size=9\n","\n","[route]\n","layers=-4\n","\n","[maxpool]\n","stride=1\n","size=13\n","\n","[route]\n","layers=-1,-3,-5,-6\n","### End SPP ###\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[route]\n","layers = -1, -13\n","\n","# 115 (previous+6+5+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# End of CSPSPP\n","\n","\n","# FPN-5\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[upsample]\n","stride=2\n","\n","[route]\n","layers = 85\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -1, -3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","# Merge [-1, -(2k+2)]\n","\n","[route]\n","layers = -1, -8\n","\n","# Transition last\n","\n","# 131 (previous+6+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# FPN-4\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[upsample]\n","stride=2\n","\n","[route]\n","layers = 70\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -1, -3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","# Merge [-1, -(2k+2)]\n","\n","[route]\n","layers = -1, -8\n","\n","# Transition last\n","\n","# 147 (previous+6+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# FPN-3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[upsample]\n","stride=2\n","\n","[route]\n","layers = 43\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -1, -3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=128\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=128\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=128\n","activation=silu\n","\n","# Merge [-1, -(2k+2)]\n","\n","[route]\n","layers = -1, -8\n","\n","# Transition last\n","\n","# 163 (previous+6+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# PAN-4\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=2\n","pad=1\n","filters=192\n","activation=silu\n","\n","[route]\n","layers = -1, 147\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[route]\n","layers = -1,-8\n","\n","# Transition last\n","\n","# 176 (previous+3+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# PAN-5\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=2\n","pad=1\n","filters=256\n","activation=silu\n","\n","[route]\n","layers = -1, 131\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[route]\n","layers = -1,-8\n","\n","# Transition last\n","\n","# 189 (previous+3+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# PAN-6\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=2\n","pad=1\n","filters=320\n","activation=silu\n","\n","[route]\n","layers = -1, 115\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[route]\n","layers = -1,-8\n","\n","# Transition last\n","\n","# 202 (previous+3+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# ============ End of Neck ============ #\n","\n","# 203\n","[implicit_add]\n","filters=256\n","\n","# 204\n","[implicit_add]\n","filters=384\n","\n","# 205\n","[implicit_add]\n","filters=512\n","\n","# 206\n","[implicit_add]\n","filters=640\n","\n","# 207\n","[implicit_mul]\n","filters={num_filters}\n","\n","# 208\n","[implicit_mul]\n","filters={num_filters}\n","\n","# 209\n","[implicit_mul]\n","filters={num_filters}\n","\n","# 210\n","[implicit_mul]\n","filters={num_filters}\n","\n","# ============ Head ============ #\n","\n","# YOLO-3\n","\n","[route]\n","layers = 163\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[shift_channels]\n","from=203\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters={num_filters}\n","activation=linear\n","\n","[control_channels]\n","from=207\n","\n","[yolo]\n","mask = 0,1,2\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes={num_classes}\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","\n","# YOLO-4\n","\n","[route]\n","layers = 176\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=384\n","activation=silu\n","\n","[shift_channels]\n","from=204\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters={num_filters}\n","activation=linear\n","\n","[control_channels]\n","from=208\n","\n","[yolo]\n","mask = 3,4,5\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes={num_classes}\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","\n","# YOLO-5\n","\n","[route]\n","layers = 189\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=512\n","activation=silu\n","\n","[shift_channels]\n","from=205\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters={num_filters}\n","activation=linear\n","\n","[control_channels]\n","from=209\n","\n","[yolo]\n","mask = 6,7,8\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes={num_classes}\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","\n","# YOLO-6\n","\n","[route]\n","layers = 202\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=640\n","activation=silu\n","\n","[shift_channels]\n","from=206\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters={num_filters}\n","activation=linear\n","\n","[control_channels]\n","from=210\n","\n","[yolo]\n","mask = 9,10,11\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes={num_classes}\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","# ============ End of Head ============ #"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1655878369522,"user":{"displayName":"adu adu","userId":"03005472707929175030"},"user_tz":-420},"id":"ZLldIGy2ERgB","outputId":"32f01cdc-cd22-4e45-d431-2c2706c7811a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","[net]\n","batch=64\n","subdivisions=8\n","width=1280\n","height=1280\n","channels=3\n","momentum=0.949\n","decay=0.0005\n","angle=0\n","saturation = 1.5\n","exposure = 1.5\n","hue=.1\n","\n","learning_rate=0.00261\n","burn_in=1000\n","max_batches = 500500\n","policy=steps\n","steps=400000,450000\n","scales=.1,.1\n","\n","mosaic=1\n","\n","\n","# ============ Backbone ============ #\n","\n","# Stem \n","\n","# P1\n","\n","# Downsample\n","\n","# 0\n","[reorg]\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P2\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=64\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=64\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-12\n","\n","# Transition last\n","\n","# 16 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P3\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=128\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-24\n","\n","# Transition last\n","\n","# 43 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P4\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=384\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=192\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-24\n","\n","# Transition last\n","\n","# 70 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=384\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P5\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=512\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=256\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-12\n","\n","# Transition last\n","\n","# 85 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=512\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# P6\n","\n","# Downsample\n","\n","[convolutional]\n","batch_normalize=1\n","filters=640\n","size=3\n","stride=2\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Residual Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=3\n","stride=1\n","pad=1\n","activation=silu\n","\n","[shortcut]\n","from=-3\n","activation=linear\n","\n","# Transition first\n","#\n","#[convolutional]\n","#batch_normalize=1\n","#filters=320\n","#size=1\n","#stride=1\n","#pad=1\n","#activation=silu\n","\n","# Merge [-1, -(3k+3)]\n","\n","[route]\n","layers = -1,-12\n","\n","# Transition last\n","\n","# 100 (previous+6+3k)\n","[convolutional]\n","batch_normalize=1\n","filters=640\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# ============ End of Backbone ============ #\n","\n","# ============ Neck ============ #\n","\n","# CSPSPP\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","### SPP ###\n","[maxpool]\n","stride=1\n","size=5\n","\n","[route]\n","layers=-2\n","\n","[maxpool]\n","stride=1\n","size=9\n","\n","[route]\n","layers=-4\n","\n","[maxpool]\n","stride=1\n","size=13\n","\n","[route]\n","layers=-1,-3,-5,-6\n","### End SPP ###\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[route]\n","layers = -1, -13\n","\n","# 115 (previous+6+5+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# End of CSPSPP\n","\n","\n","# FPN-5\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[upsample]\n","stride=2\n","\n","[route]\n","layers = 85\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -1, -3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","# Merge [-1, -(2k+2)]\n","\n","[route]\n","layers = -1, -8\n","\n","# Transition last\n","\n","# 131 (previous+6+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# FPN-4\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[upsample]\n","stride=2\n","\n","[route]\n","layers = 70\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -1, -3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","# Merge [-1, -(2k+2)]\n","\n","[route]\n","layers = -1, -8\n","\n","# Transition last\n","\n","# 147 (previous+6+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# FPN-3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[upsample]\n","stride=2\n","\n","[route]\n","layers = 43\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -1, -3\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=128\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=128\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=128\n","activation=silu\n","\n","# Merge [-1, -(2k+2)]\n","\n","[route]\n","layers = -1, -8\n","\n","# Transition last\n","\n","# 163 (previous+6+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=128\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# PAN-4\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=2\n","pad=1\n","filters=192\n","activation=silu\n","\n","[route]\n","layers = -1, 147\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=192\n","activation=silu\n","\n","[route]\n","layers = -1,-8\n","\n","# Transition last\n","\n","# 176 (previous+3+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=192\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# PAN-5\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=2\n","pad=1\n","filters=256\n","activation=silu\n","\n","[route]\n","layers = -1, 131\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[route]\n","layers = -1,-8\n","\n","# Transition last\n","\n","# 189 (previous+3+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=256\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","\n","# PAN-6\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=2\n","pad=1\n","filters=320\n","activation=silu\n","\n","[route]\n","layers = -1, 115\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# Split\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[route]\n","layers = -2\n","\n","# Plain Block\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=320\n","activation=silu\n","\n","[route]\n","layers = -1,-8\n","\n","# Transition last\n","\n","# 202 (previous+3+4+2k)\n","[convolutional]\n","batch_normalize=1\n","filters=320\n","size=1\n","stride=1\n","pad=1\n","activation=silu\n","\n","# ============ End of Neck ============ #\n","\n","# 203\n","[implicit_add]\n","filters=256\n","\n","# 204\n","[implicit_add]\n","filters=384\n","\n","# 205\n","[implicit_add]\n","filters=512\n","\n","# 206\n","[implicit_add]\n","filters=640\n","\n","# 207\n","[implicit_mul]\n","filters=36\n","\n","# 208\n","[implicit_mul]\n","filters=36\n","\n","# 209\n","[implicit_mul]\n","filters=36\n","\n","# 210\n","[implicit_mul]\n","filters=36\n","\n","# ============ Head ============ #\n","\n","# YOLO-3\n","\n","[route]\n","layers = 163\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=256\n","activation=silu\n","\n","[shift_channels]\n","from=203\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters=36\n","activation=linear\n","\n","[control_channels]\n","from=207\n","\n","[yolo]\n","mask = 0,1,2\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes=7\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","\n","# YOLO-4\n","\n","[route]\n","layers = 176\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=384\n","activation=silu\n","\n","[shift_channels]\n","from=204\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters=36\n","activation=linear\n","\n","[control_channels]\n","from=208\n","\n","[yolo]\n","mask = 3,4,5\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes=7\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","\n","# YOLO-5\n","\n","[route]\n","layers = 189\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=512\n","activation=silu\n","\n","[shift_channels]\n","from=205\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters=36\n","activation=linear\n","\n","[control_channels]\n","from=209\n","\n","[yolo]\n","mask = 6,7,8\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes=7\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","\n","# YOLO-6\n","\n","[route]\n","layers = 202\n","\n","[convolutional]\n","batch_normalize=1\n","size=3\n","stride=1\n","pad=1\n","filters=640\n","activation=silu\n","\n","[shift_channels]\n","from=206\n","\n","[convolutional]\n","size=1\n","stride=1\n","pad=1\n","filters=36\n","activation=linear\n","\n","[control_channels]\n","from=210\n","\n","[yolo]\n","mask = 9,10,11\n","anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n","classes=7\n","num=12\n","jitter=.3\n","ignore_thresh = .7\n","truth_thresh = 1\n","random=1\n","scale_x_y = 1.05\n","iou_thresh=0.213\n","cls_normalizer=1.0\n","iou_normalizer=0.07\n","iou_loss=ciou\n","nms_kind=greedynms\n","beta_nms=0.6\n","\n","# ============ End of Head ============ #"]}],"source":["%cat /content/yolor/cfg/yolor_p6.cfg"]},{"cell_type":"markdown","metadata":{"id":"o6t4nA4wWr8v"},"source":["# Train Custom YOLOR Detector\n","\n","### Next, we'll fire off training!\n","\n","\n","Here, we are able to pass a number of arguments:\n","- **img:** define input image size\n","- **batch:** determine batch size\n","- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n","- **data:** set the path to our yaml file\n","- **cfg:** specify our model configuration\n","- **weights:** specify a custom path to weights. (Note: We can specify the pretrained weights we downloaded up above with the shell script)\n","- **name:** result names\n","-**hyp:** Define the hyperparamters for training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-w0P5Pw-pd9a"},"outputs":[],"source":["%cp /content/drive/MyDrive/yolor_p6.pt /content -r"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7PKH6ufhkwu"},"outputs":[],"source":["%cp /content/drive/MyDrive/runs /content/yolor -r"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"OqG-CDJZEiw2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolor\n","Resuming training from ./runs/train/yolor_p6/weights/last.pt\n","Using torch 1.7.0 CUDA:0 (Tesla T4, 15109MB)\n","\n","Namespace(adam=False, batch_size=8, bucket='', cache_images=False, cfg='/content/yolor/cfg/yolor_p6.cfg', data='/content/yolor/RDD-2/data.yaml', device='0', epochs=100, evolve=False, exist_ok=False, global_rank=-1, hyp='/content/yolor/data/hyp.scratch.1280.yaml', image_weights=False, img_size=[416, 416], local_rank=-1, log_imgs=16, multi_scale=False, name='yolor_p6', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=True, save_dir='runs/train/yolor_p6', single_cls=False, sync_bn=False, total_batch_size=8, weights='./runs/train/yolor_p6/weights/last.pt', workers=8, world_size=1)\n","Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n","NumExpr defaulting to 2 threads.\n","Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n","Model Summary: 665 layers, 36870816 parameters, 36870816 gradients\n","Transferred 862/862 items from ./runs/train/yolor_p6/weights/last.pt\n","Optimizer groups: 145 .bias, 145 conv.weight, 149 other\n","WARNING: --img-size 416 must be multiple of max stride 64, updating to 448\n","WARNING: --img-size 416 must be multiple of max stride 64, updating to 448\n","Scanning labels RDD-2/train/labels.cache3 (20898 found, 0 missing, 755 empty, 0 duplicate, for 21653 images): 21653it [00:01, 16514.66it/s]\n","Scanning labels RDD-2/valid/labels.cache3 (904 found, 0 missing, 96 empty, 0 duplicate, for 1000 images): 1000it [00:00, 10655.29it/s]\n","Image sizes 448 train, 448 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolor_p6\n","Starting training for 100 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     93/99     2.85G  0.008347   0.01188  0.003031   0.02326        15       448: 100% 2707/2707 [10:39\u003c00:00,  4.24it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 63/63 [00:10\u003c00:00,  5.80it/s]\n","                 all       1e+03    2.19e+03       0.592       0.472       0.506        0.25\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     94/99     2.54G  0.008551   0.01212   0.00304   0.02371        20       448: 100% 2707/2707 [10:26\u003c00:00,  4.32it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 63/63 [00:09\u003c00:00,  6.48it/s]\n","                 all       1e+03    2.19e+03       0.589       0.471       0.506        0.25\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     95/99     2.54G  0.008607   0.01218  0.003086   0.02387        13       448: 100% 2707/2707 [10:27\u003c00:00,  4.31it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 63/63 [00:09\u003c00:00,  6.46it/s]\n","                 all       1e+03    2.19e+03        0.59       0.472       0.506        0.25\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     96/99     2.54G   0.00858   0.01217  0.002939   0.02368        10       448: 100% 2707/2707 [10:26\u003c00:00,  4.32it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 63/63 [00:09\u003c00:00,  6.47it/s]\n","                 all       1e+03    2.19e+03       0.589       0.471       0.506       0.251\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     97/99     2.54G  0.008665   0.01226  0.003037   0.02396        19       448: 100% 2707/2707 [10:16\u003c00:00,  4.39it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 63/63 [00:09\u003c00:00,  6.52it/s]\n","                 all       1e+03    2.19e+03       0.591       0.471       0.506       0.251\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     98/99     2.54G  0.008762   0.01236   0.00324   0.02436         8       448: 100% 2707/2707 [10:14\u003c00:00,  4.40it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95: 100% 63/63 [00:09\u003c00:00,  6.60it/s]\n","                 all       1e+03    2.19e+03       0.592       0.472       0.506       0.252\n","\n","     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n","     99/99     2.54G  0.008719   0.01249  0.003346   0.02456        10       448: 100% 2707/2707 [10:15\u003c00:00,  4.40it/s]\n","               Class      Images     Targets           P           R      mAP@.5  mAP@.5:.95:   0% 0/63 [00:00\u003c?, ?it/s]\n","Traceback (most recent call last):\n","  File \"train.py\", line 537, in \u003cmodule\u003e\n","    train(hyp, opt, device, tb_writer, wandb)\n","  File \"train.py\", line 344, in train\n","    log_imgs=opt.log_imgs if wandb else 0)\n","  File \"/content/yolor/test.py\", line 226, in test\n","    plot_images(img, output_to_target(output, width, height), paths, f, names)  # predictions\n","  File \"/content/yolor/utils/plots.py\", line 108, in output_to_target\n","    return np.array(targets)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 630, in __array__\n","    return self.numpy()\n","TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n"]}],"source":["%cd /content/yolor\n","!python train.py --batch-size 8 --img 416 416 --data {dataset.location}/data.yaml --cfg cfg/yolor_p6.cfg --weights '/content/yolor_p6.pt' --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 100 --resume"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QV-YoyJpYfeN"},"outputs":[],"source":["%cp /content/yolor/runs /content/drive/MyDrive -r"]},{"cell_type":"markdown","metadata":{"id":"FAbe94smXcg0"},"source":["# Evaluate Custom YOLOR Detector Performance\n","\n","Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolor_p6`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Kha-ehkX1qP"},"outputs":[],"source":["# Start tensorboard\n","# Launch after you have started training\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MGnkowATX4ZS"},"outputs":[],"source":["from IPython.display import Image\n","# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n","from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolor/runs/train/yolor_p6/results.png', width=1000)  # view results.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jyp7zrtBX6wc"},"outputs":[],"source":["# first, display our ground truth data\n","print(\"GROUND TRUTH TRAINING DATA:\")\n","Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDDz3cWgq4gQ"},"outputs":[],"source":["print(\"AUGMENTED DATA:\")\n","Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"]},{"cell_type":"markdown","metadata":{"id":"mqYf31oCYYRn"},"source":["#Run Inference  With Trained Weights\n","Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QwuHFc3nYf7J"},"outputs":[],"source":["# trained weights are saved by default in our weights folder\n","%ls runs/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liYDNniHYiKq"},"outputs":[],"source":["%ls runs/train/yolor_p6/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLG0HPpbtpK0"},"outputs":[],"source":["# Create names file for model\n","import yaml\n","import ast\n","with open(\"../data.yaml\", 'r') as stream:\n","    names = str(yaml.safe_load(stream)['names'])\n","\n","namesFile = open(\"../data.names\", \"w+\")\n","names = ast.literal_eval(names)\n","for name in names:\n","  namesFile.write(name +'\\n')\n","namesFile.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfObNHTCYqih"},"outputs":[],"source":["!python detect.py --weights \"runs/train/yolor_p6/weights/best_overall.pt\" --conf 0.5 --source ../test/images --names ../data.names --cfg cfg/yolor_p6.cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBeuZJA4s2Zh"},"outputs":[],"source":["#display inference on ALL test images\n","#this looks much better with longer training above\n","\n","import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob('/content/yolor/inference/output/*.jpg'): #assuming JPG\n","    display(Image(filename=imageName))\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"_XUnMCThYM3W"},"source":["# Export Trained Weights for Future Inference\n","\n","Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mP8-UrwiYP8j"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZ-zspK3YQlr"},"outputs":[],"source":["%cp /content/yolor/runs/train/yolor_p6/weights/best.pt /content/gdrive/My\\ Drive"]},{"cell_type":"markdown","metadata":{"id":"dQrUGu9nYI-T"},"source":["## Congrats!\n","\n","Hope you enjoyed this!\n","\n","--Team [Roboflow](https://roboflow.ai)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Bản_sao_của_Training_YOLOR_on_a_Custom_Dataset_(1).ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}